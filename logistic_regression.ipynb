{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f880a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a21560b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, dataset_path=None):\n",
    "        self.path = dataset_path\n",
    "\n",
    "    def get_data(self):\n",
    "        data = pd.read_csv(self.path).to_numpy()\n",
    "        X, Y_str = data[:, :-1], data[:, -1]  # remove the target column from the input and extract our targets\n",
    "        if X.ndim == 1:\n",
    "            X = X.reshape(-1, 1) # force X to be 2D\n",
    "        # n_classes = len(set(Y_str))\n",
    "        n_examples = len(Y_str)\n",
    "        Y = np.zeros(n_examples)\n",
    "        for i in range(len(Y_str)):\n",
    "            category = Y_str[i]\n",
    "            if category == \"banana\": Y[i] = 0\n",
    "            elif category == \"carrot\": Y[i] = 1\n",
    "            elif category == \"cucumber\": Y[i] = 2\n",
    "            elif category == \"mandarin\": Y[i] = 3\n",
    "            else: Y[i] = 4\n",
    "        return X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d437f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, num_iters=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iters = num_iters\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.loss_hist = []\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    def predict_raw(self, X):\n",
    "        return np.dot(X, self.weights) + self.bias\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        return self.sigmoid(self.predict_raw(X))\n",
    "    \n",
    "    def logisticLoss(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "            binary cross entropy\n",
    "        \"\"\"\n",
    "        y0 = y_true * np.log(y_pred)\n",
    "        y1 = (1 - y_true) * np.log(1 - y_pred)\n",
    "        return -np.mean(y0 + y1)\n",
    "    \n",
    "    def train(self, X_train, Y_train, X_val=None, Y_val=None):\n",
    "        # Set the proper data type to avoid errors with numpy\n",
    "        X_train, Y_train = X_train.astype(float), Y_train.astype(float)\n",
    "        X_val = X_val.astype(float) if X_val is not None else None\n",
    "        Y_val = Y_val.astype(float) if Y_val is not None else None\n",
    "\n",
    "        # Compute and store normalization params (TRAIN ONLY)\n",
    "        self.mean = X_train.mean(axis=0)\n",
    "        self.std = X_train.std(axis=0)\n",
    "        self.std[self.std == 0] = 1  # avoid division by zero\n",
    "\n",
    "       # \n",
    "\n",
    "        n_examples, n_features = X_train.shape\n",
    "\n",
    "        self.weights        = np.zeros(n_features)\n",
    "        self.bias           = 0\n",
    "        self.loss_hist      = []\n",
    "        self.val_loss_hist  = []\n",
    "        \n",
    "        for i in range(self.num_iters):\n",
    "            # Forward\n",
    "            y_pred = self.sigmoid(np.dot(X_train, self.weights) + self.bias)\n",
    "            train_loss = self.logisticLoss(Y_train, y_pred)\n",
    "\n",
    "            # gradient of binary cross entropy\n",
    "            y_diff = (y_pred - Y_train)\n",
    "            self.weights -= self.learning_rate * np.dot(X_train.T, y_diff) / n_examples\n",
    "            self.bias    -= self.learning_rate * np.mean(y_diff)\n",
    "            \n",
    "            # Save loss\n",
    "            self.loss_hist.append(train_loss)\n",
    "\n",
    "            # Validation\n",
    "            if X_val is not None:\n",
    "                val_pred = self.predict_proba(X_val)\n",
    "                self.val_loss_hist.append(self.logisticLoss(Y_val, val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ad20652",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionOVA:\n",
    "    def __init__(self, learning_rate=0.01, num_iters=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_iters = num_iters\n",
    "        self.models = []\n",
    "        self.classes = None\n",
    "\n",
    "    def train(self, X_train, Y_train, X_val=None, Y_val=None):\n",
    "        self.classes = np.unique(Y_train)\n",
    "        self.models = []\n",
    "\n",
    "        for cls in self.classes:\n",
    "            print(f\"Train class {cls} vs rest\")\n",
    "            Y_binary_train  = (Y_train == cls).astype(float)\n",
    "            Y_binary_val    = (Y_val == cls).astype(float) if Y_val is not None else None\n",
    "            \n",
    "            model = LogisticRegression(learning_rate=self.learning_rate, num_iters=self.num_iters)\n",
    "            model.train(X_train, Y_binary_train, X_val, Y_binary_val)\n",
    "            self.models.append(model)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Data type and normalization\n",
    "        X = X.astype(float)\n",
    "        #\n",
    "        all_probs = []\n",
    "\n",
    "        for model in self.models:\n",
    "            probs = model.predict_proba(X)\n",
    "            all_probs.append(probs)\n",
    "\n",
    "        all_probs = np.column_stack(all_probs)\n",
    "        max_idx = np.argmax(all_probs, axis=1)\n",
    "        return self.classes[max_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f19a6758",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_ova_loss(models, classes, feature_set):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    for model, cls in zip(models, classes):\n",
    "        plt.plot(model.loss_hist, label=f\"Train Loss (class {cls})\")\n",
    "        if len(model.val_loss_hist) > 0:\n",
    "            plt.plot(model.val_loss_hist, '--', label=f\"Val Loss (class {cls})\")\n",
    "\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(f\"Training vs Validation Loss ({feature_set})\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dde52326",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_basic_metrics(y_true, y_pred):\n",
    "    \"\"\"Accuracy, Precision, Recall, F1 (macro).\"\"\"\n",
    "    return {\n",
    "        \"accuracy\":  accuracy_score(y_true, y_pred),\n",
    "        \"precision\": precision_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
    "        \"recall\":    recall_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
    "        \"f1\":        f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "    }\n",
    "\n",
    "def compute_multiclass_roc_auc(model_ova, X, y_true):\n",
    "    \"\"\"\n",
    "    Multiclass ROC-AUC = macro average of OvA ROC curves.\n",
    "    Uses predicted probabilities from each class-model.\n",
    "    \"\"\"\n",
    "    X = X.astype(float)\n",
    "    X = (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "\n",
    "    # Collect probabilities from each model by shape (n_samples, n_classes)\n",
    "    prob_matrix = []\n",
    "    for m in model_ova.models:\n",
    "        prob_matrix.append(m.predict_proba(X))\n",
    "\n",
    "    prob_matrix = np.column_stack(prob_matrix)\n",
    "\n",
    "    try:\n",
    "        auc = roc_auc_score(y_true, prob_matrix, multi_class=\"ovr\", average=\"macro\")\n",
    "    except ValueError:\n",
    "        auc = np.nan  # if a class is missing\n",
    "\n",
    "    return auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4d23269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for feature set: images\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "loop of ufunc does not support argument 0 of type float which has no callable sqrt method",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[31mAttributeError\u001b[39m: 'float' object has no attribute 'sqrt'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     34\u001b[39m X_val,   Y_val   = load_split(\u001b[33m\"\u001b[39m\u001b[33mvalidation\u001b[39m\u001b[33m\"\u001b[39m, name)\n\u001b[32m     35\u001b[39m X_test,  Y_test  = load_split(\u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m, name)\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m X_train, X_val, X_test = \u001b[43mnormalize_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Train OVA classifier\u001b[39;00m\n\u001b[32m     40\u001b[39m model = LogisticRegressionOVA(learning_rate=\u001b[32m0.01\u001b[39m, num_iters=\u001b[32m1000\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36mnormalize_split\u001b[39m\u001b[34m(X_train, X_val, X_test)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnormalize_split\u001b[39m(X_train, X_val, X_test):\n\u001b[32m      8\u001b[39m     mean = X_train.mean(axis=\u001b[32m0\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     std = \u001b[43mX_train\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstd\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     std[std == \u001b[32m0\u001b[39m] = \u001b[32m1\u001b[39m  \u001b[38;5;66;03m# wichtig!\u001b[39;00m\n\u001b[32m     13\u001b[39m     X_train_norm = (X_train - mean) / std\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\saura\\miniconda3\\envs\\ml\\Lib\\site-packages\\numpy\\_core\\_methods.py:227\u001b[39m, in \u001b[36m_std\u001b[39m\u001b[34m(a, axis, dtype, out, ddof, keepdims, where, mean)\u001b[39m\n\u001b[32m    223\u001b[39m ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n\u001b[32m    224\u001b[39m            keepdims=keepdims, where=where, mean=mean)\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, mu.ndarray):\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m     ret = \u001b[43mum\u001b[49m\u001b[43m.\u001b[49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mret\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mret\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    228\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ret, \u001b[33m'\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    229\u001b[39m     ret = ret.dtype.type(um.sqrt(ret))\n",
      "\u001b[31mTypeError\u001b[39m: loop of ufunc does not support argument 0 of type float which has no callable sqrt method"
     ]
    }
   ],
   "source": [
    "# Load all 4 feature sets\n",
    "def load_split(split_name, features):\n",
    "    path = f\"./data/tabular/{split_name}_{features}_processed.csv\"\n",
    "    ds = Dataset(path)\n",
    "    return ds.get_data()\n",
    "\n",
    "def normalize_split(X_train, X_val, X_test):\n",
    "    mean = X_train.mean(axis=0)\n",
    "    std = X_train.std(axis=0)\n",
    "\n",
    "    std[std == 0] = 1  # wichtig!\n",
    "\n",
    "    X_train_norm = (X_train - mean) / std\n",
    "    X_val_norm   = (X_val   - mean) / std\n",
    "    X_test_norm  = (X_test  - mean) / std\n",
    "\n",
    "    return X_train_norm, X_val_norm, X_test_norm\n",
    "\n",
    "# List of feature set\n",
    "feature_sets = [\n",
    "    \"images\",\n",
    "    \"tabular\",\n",
    "    \"text\",\n",
    "    \"fusion\"\n",
    "]\n",
    "\n",
    "trained_models = {}\n",
    "\n",
    "for name in feature_sets:\n",
    "    print(f\"Training model for feature set: {name}\")\n",
    "\n",
    "    # Load feature-specific data\n",
    "    X_train, Y_train = load_split(\"train\", name)\n",
    "    X_val,   Y_val   = load_split(\"validation\", name)\n",
    "    X_test,  Y_test  = load_split(\"test\", name)\n",
    "\n",
    "    X_train, X_val, X_test = normalize_split(X_train, X_val, X_test)\n",
    "\n",
    "    # Train OVA classifier\n",
    "    model = LogisticRegressionOVA(learning_rate=0.01, num_iters=1000)\n",
    "    model.train(X_train, Y_train, X_val, Y_val)\n",
    "\n",
    "    # Save in dictionary\n",
    "    trained_models[name] = {\n",
    "        \"model\": model,\n",
    "        \"feature_set\": name,\n",
    "        \"train_pred\": model.predict(X_train),\n",
    "        \"val_pred\": model.predict(X_val),\n",
    "        \"test_pred\": model.predict(X_test),\n",
    "        \"Y_train\": Y_train,\n",
    "        \"Y_val\": Y_val,\n",
    "        \"Y_test\": Y_test\n",
    "    }\n",
    "\n",
    "print(\"All four models are trained.\")\n",
    "\n",
    "# Compute metrics for all models\n",
    "results = {}\n",
    "\n",
    "for name, data in trained_models.items():\n",
    "    print(f\"Metrics for feature set: {name}\")\n",
    "\n",
    "    model = data[\"model\"]\n",
    "\n",
    "    # Predictions\n",
    "    y_train_pred = data[\"train_pred\"]\n",
    "    y_val_pred   = data[\"val_pred\"]\n",
    "    y_test_pred  = data[\"test_pred\"]\n",
    "\n",
    "    # Ground truth\n",
    "    Y_train = data[\"Y_train\"]\n",
    "    Y_val   = data[\"Y_val\"]\n",
    "    Y_test  = data[\"Y_test\"]\n",
    "\n",
    "    # Basic metrics\n",
    "    metrics_train = compute_basic_metrics(Y_train, y_train_pred)\n",
    "    metrics_val   = compute_basic_metrics(Y_val,   y_val_pred)\n",
    "    metrics_test  = compute_basic_metrics(Y_test,  y_test_pred)\n",
    "\n",
    "    # ROC-AUC (macro multiclass)\n",
    "    auc_train = compute_multiclass_roc_auc(model, X_train, Y_train)\n",
    "    auc_val   = compute_multiclass_roc_auc(model, X_val,   Y_val)\n",
    "    auc_test  = compute_multiclass_roc_auc(model, X_test,  Y_test)\n",
    "\n",
    "    metrics_train[\"roc_auc\"] = auc_train\n",
    "    metrics_val[\"roc_auc\"]   = auc_val\n",
    "    metrics_test[\"roc_auc\"]  = auc_test\n",
    "\n",
    "    # Store all\n",
    "    results[name] = {\n",
    "        \"train\": metrics_train,\n",
    "        \"val\":   metrics_val,\n",
    "        \"test\":  metrics_test\n",
    "    }\n",
    "\n",
    "    # Pretty print\n",
    "    print(\"Train:\", metrics_train)\n",
    "    print(\"Val:  \", metrics_val)\n",
    "    \n",
    "    print(\"Test: \", metrics_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac56d61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, data in trained_models.items():\n",
    "    print(f\"\\nPlotting losses for feature set: {name}\")\n",
    "    plot_ova_loss(data[\"model\"].models, data[\"model\"].classes, data[\"feature_set\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
